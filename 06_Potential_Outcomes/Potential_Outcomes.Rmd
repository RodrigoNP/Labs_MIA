---
title: "Potentianl Outcomes"
author: "Rodrigo Negrete Pérez"
date: \today

theme: "CambridgeUS"
colortheme: 'beaver'
output: 
  beamer_presentation:
    slide_level: 2
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
library(tidyverse)
library(xtable)
options(xtable.comment = FALSE)
```

# Introducción 

## Introducción

El hilo conductor del curso es la pregunta de la causalidad

* No cualquier tipo de pregunta causal
  + ¿Cuál es el efecto de A sobre B?

* A manera de ejemplo: efecto del la educación superior sobre el salario 
     
## Educación y salario   

* Parece intuitivo, pero pueden pasar muchas cosas en medio de la relación
* ¿Cuál es el efecto... de le educación?
* Podemos planter un modelo: con datos simulados podemos saber qué estima nuestro modelo
  + Si estimamos con sesgo
  + ventajas y desventajas
  
# Potential Outcomes  

## Potential Outcomes
Suponemos que la entidad tiene dos posibles resultados: bajo tratamiento y sin tratamiento (control)

* Si Rodrigo va a la universidad, su salario sería de 80k mensuales
* Si no va a la universidad, su salario sería de 25k

Entonces, denotamos $Y_{0R}=25$ al outcome bajo control y $Y_{1R}=80$ al outcome bajo tratamiento

## Problema fundamental de la inferencia causal

El problema es que solo observamos uno de los dos posibles potential outcomes:

* Si Rodrigo va a la uni, observaré $Y_{1R}$
* Si no, $Y_{0R}$

\begin{equation}
Y_i=
  \begin{cases}
  Y_{1i} , & \text{si}\ t=1\\
  Y_{0i} , & \text{si}\ t=0
  \end{cases}
\end{equation}  

Entonces, podemos escribir la Y observada como 

\[ Y_i=Y_{0i}+(Y_{1i}-Y_{01}) T_i \]

## Generación de P.O.

Vamos a generar los Potential Outcomes

Supongamos que: 

* $Y_{0i}~N(30, 10)$
* $Y_{1i}~N(50, 35)$

```{r, results='hide'}
set.seed(2022)
n<-10000
i<-1:n
y0<-rnorm(n, 30, 10)
y1<-rnorm(n, 50, 35)
df<-data.frame(i,y0,y1)
```

## 

```{r, echo=FALSE}
head(df)
```

## Asignación del tratamiento

Tenemos que asignar el tratamiento

* Podríamos hacerlo con un vector de 1 y 0, y que t sea equiprobable: simple random assignment
* Podríamos asignar t a mitad de la muestra: complete random assignment
* Para complete ra es más práctico usar el paquete randomizr: complete_ra( )

```{r, results='hide', warning=FALSE}
library(randomizr)
```

##

```{r, include=FALSE}
df<-mutate(df, t=complete_ra(n))
```

```{r, echo=FALSE, results='asis'}
xtable(head(df), caption = NULL)
```

##

Así, podemos añadir la Y observada

```{r}
df<-mutate(df,y_observada=y0+(y1-y0)*t)
```

```{r, results='asis', echo=FALSE}
xtable(head(df), caption = NULL)
```

# Efectos Causales

## Efecto Causal Individual

Cuando tenemos ambos P.O. podemos calcular el
**Efecto Causal Individual** ($\delta_i$) tomando la diferencia entre $Y_{1i}$ y $Y_{0i}$

\[ \delta_i=Y_{1i}-Y_{0i} \]

* Por ejemplo, decimos que el efecto de la uni en Rodrigo es de $\delta_R=80-25$ pesos mensuales

* Hay una gran heterogeneidad en los efectos causales individuales
 + Hay `r length(df[y0>y1, ])` individuos cuyo salario es mayor sin universidad
 
## 

```{r, results='hide'}
df<-mutate(df, delta=y1-y0)
```

```{r, results='asis', echo=FALSE}
xtable(head(df))
```

## Efecto Causal Promedio ##

* Nos importa el efecto que tiene la uni en general: el efecto promedio

\[ ATE=E[Y_{1i}-Y_{0i}]= E[\delta_i] \]

* Basta con tomar el promedio de los efectos causales individuales, pero para toda la muestra. 


## Efecto promedio sobre los tratados

* De igual manera, podemos calcular el efecto promedio, pero sobre los tratados

\[ ATT=E[Y_{1i}-Y{0i}| T_i = 1]\]

* Es calcular el ATE, pero solo para aquellos que fueron tratados. 

## Efecto promedio sobre los controles

* Análogamente, el ATC es el ATE, pero consideramos solo a aquellos que fueron controles

\[ ATC=E[Y_{1i}-Y{0i}| T_i=0]\]

## 

* Con datos generados es muy fácil calcular los efectos causales
* Tomamos los efectos causales individuales, los dividimos en subconjuntos, y luego calculamos promedios
* En R, las funciones **filter()** y **with()** nos van a ser muy útiles

```{r}
ate<-with(df, mean(delta))
att<-with(filter(df, t==1), mean(delta))
atc<-with(filter(df, t==0), mean(delta))
```

##

* Obetenemos que el ATE=`r ate`
  + ATT=`r att`
  + ATC=`r atc`

## Contraste Ingenuo

* Sin embargo, el investigador no puede observar estos efectos. Ninguno es observable
* Lo que el investigador puede observar es el Contraste ingenuo: el promedio del outcome para los tratados menos el promedio del outcome para los no tratados

\[ CI= E[Y_{1i} |T_i=1]-E[Y_{0i}|T_i=0] \]


## 

* En nuestro df definimos las y_observada(s)
* Para calcular el CI, basta calcular el promedio de las y_observadas de los que fueron tratados, y restarle el promedio de las y_observadas de los controles.

```{r}
ci<-with(filter(df, t==1), 
         mean(y_observada))- 
  with(filter(df, t==0), 
          mean(y_observada))
```

##

* Obtenemos un CI=`r ci`, el cual es muy parecido al ATE=`r ate`
* Entonces, ¿por qué tanto problema?


# Simulaciones

## Virtudes de las simulaciones

* Los datos que generamos provienen de una distribución normal. 
* Podemos calcular muchas cosas usando cálculo diferencial. 
  + Por ejemplo, ya sabíamos que el ATE iba a ser de 20
  + Sin embargo, por el elemento aleatorio no dio 20, sino `r ate`
  + Pero no siempre será tan fácil como aplicar las propiedades de la normal. 
* Alternativamente al cálculo diferencial, podemos hacer el cálculo muchas muchas veces y ver hacia dónde tiende

##

* Por ejemplo, ¿nuestro CI coincidió con el ATE por el elemento aleatorio? ¿Fue una casualidad? 

* ¡Simulemos! Hagamos el mismo cálculo, pero varias veces: para cada df tomemos el ATE y el CI.  
* En R, podemos hacerlo fácilmente con un FOR loop. 

* Hagámoslo unas 5000 veces

```{r}
numrep<-5000
```

##

* Preparemos el loop
* Luego podremos mover el número de repeticiones y la cantidad de individuos

```{r, results='hide', cache=TRUE}
set.seed(2022)
#semilla
numrep<-5000
n<-10000

ate_estimates<-NULL #vectores vacios
ci_estimates<-NULL  # para guardar datos

```

##

```{r, results='hide', cache=TRUE}
for (i in 1:numrep) {
  # Creacion df
df<-data.frame(i=1:n,
               y0=rnorm(n, 30, 10),
               y1=rnorm(n, 50, 35),
               t=complete_ra(n)) %>% 
  mutate(y_observada=y0+(y1-y0)*t,
         delta=y1-y0)

  # Calculo efectos causales
# Debemos guardarlos como entrada en vectores
ate_estimates[i]<- with(df, mean(delta))

ci_estimates[i]<- with(filter(df, t==1), 
         mean(y_observada))- 
  with(filter(df, t==0), 
          mean(y_observada))        
}
```

##

* Hagamos un análisis visual
* Hagamos un histograma para los ATE's y otro para los CI's

```{r, eval=FALSE}
ggplot()+
  geom_histogram(aes(ate_estimates),
                 fill='red', alpha=.5, 
                 bins = 100)+
  geom_histogram(aes(ci_estimates),
                 fill='blue', alpha=.5,
                 bins=100)+
  geom_vline(xintercept = mean(ate_estimates),
             color='red')+
  geom_vline(xintercept = mean(ci_estimates),
             color='blue')+
  xlab('')
  
  
```

##

```{r, echo=FALSE, cache=TRUE}
ggplot()+
  geom_histogram(aes(ate_estimates),
                 fill='red', alpha=.5, 
                 bins = 100)+
  geom_histogram(aes(ci_estimates),
                 fill='blue', alpha=.5,
                 bins=100)+
  geom_vline(xintercept = mean(ate_estimates),
             color='red')+
  geom_vline(xintercept = mean(ci_estimates),
             color='blue')+
  xlab('')
  
  
```

##

* Tratemos de graficar las diferencias

```{r, results='hide'}
error_estimates<-ate_estimates-
  ci_estimates
```

* Hacemos un vector porque ggplot requiere un df

##

```{r, eval=FALSE}
ggplot()+
  geom_histogram(aes(x=error_estimates),
                 bins = 100)+
  geom_vline(xintercept = 
               mean(error_estimates))
```

##

```{r, echo=F, cache=TRUE}
ggplot()+
  geom_histogram(aes(x=error_estimates),
                 bins = 100)+
  geom_vline(xintercept = 
               mean(error_estimates))
```


## 

* Podríamos concluir que el CI estima insesgadamente el ATE... peeeroo
* Nos apoyamos en algunos SUPUESTOS

# Sesgo de selección

## Unconfoundedness

En el centro de todas las estrategias de identificación yace el supuesto de **Unconfoundedness**

* Una vez condicionemos sobre todo lo que tenemos que controlar, la asignación del tratamiento es cuasialeatoria

* La asignación del tratamiento no puede depender de los Potential Outcomes

* Si los individuos se tratan porque creen que el tratamiento les va a funcionar, se estan **autoseleccionando**. 

## Asignación aleatoria del tratamiento

* La asignación aleatoria del tratamiento (junto con la Ley de los Grandes Números) garantiza que la asignación aleatoria del tratamiento no depende de los P.O. 

* En nuestras simulaciones, la asignación de t siempre fue aleatoria

## Autoselección

* Repitamos las simulaciones, pero cambiemos la asignación de t
* Hagamos que t dependa de los P.O.

  
## 

* La Educación universitaria es costosa
  + Costos monetarios
  + Costos de oportunidad
  + Tiempo
  
* Supongamos que solo se tratan aquellos para los que la uni les mejora considerablemente el salario mensual 

* Supongamos que:

\begin{equation}
T_i=
  \begin{cases}
  1 , & \text{si}\ Y_{1i}-Y_{0i}>10 \\
  0, & \text{e.o.c.}\\ 
  \end{cases}
\end{equation} 

##


```{r, eval=FALSE}
set.seed(2022)
#semilla
numrep<-5000
n<-10000

ate_estimates<-NULL #vectores vacios
ci_estimates<-NULL  # para guardar datos

```

##

```{r, eval=FALSE}
for (i in 1:numrep) {
  # Creacion df
df<-data.frame(i=1:n,
               y0=rnorm(n, 30, 10),
               y1=rnorm(n, 50, 35)) %>% 
  mutate(t=ifelse(y1-y0>10,1,0), #Cambiamos t
    y_observada=y0+(y1-y0)*t,
         delta=y1-y0)

  # Calculo efectos causales
# Debemos guardarlos como entrada en vectores
ate_estimates[i]<- with(df, mean(delta))

ci_estimates[i]<- with(filter(df, t==1), 
         mean(y_observada))- 
  with(filter(df, t==0), 
          mean(y_observada))        
}
```

##

```{r, echo=FALSE, cache=TRUE}
set.seed(2022)
#semilla
numrep<-5000
n<-10000

ate_estimates<-NULL #vectores vacios
ci_estimates<-NULL

for (i in 1:numrep) {
  # Creacion df
df<-data.frame(i=1:n,
               y0=rnorm(n, 30, 10),
               y1=rnorm(n, 50, 35)) %>% 
  mutate(t=ifelse(y1-y0>10,1,0), #Cambiamos t
    y_observada=y0+(y1-y0)*t,
         delta=y1-y0)

  # Calculo efectos causales
# Debemos guardarlos como entrada en vectores
ate_estimates[i]<- with(df, mean(delta))

ci_estimates[i]<- with(filter(df, t==1), 
         mean(y_observada))- 
  with(filter(df, t==0), 
          mean(y_observada))        
}

ggplot()+
  geom_histogram(aes(ate_estimates),
                 fill='red', alpha=.5, 
                 bins = 100)+
  geom_histogram(aes(ci_estimates),
                 fill='blue', alpha=.5,
                 bins=100)+
  geom_vline(xintercept = mean(ate_estimates),
             color='red')+
  geom_vline(xintercept = mean(ci_estimates),
             color='blue')+
  xlab('')
  
  
```

## 

* La diferencia es dramática:
  + El promedio de nuestros ATE's es `r mean(ate_estimates) `, mientras que el promedio de los CI's es `r mean(ci_estimates) `
  
* Nuestro CI tiende a sobreestimar el efecto real de la uni (y por mucho)
* Extrapolando: si los individuos se autoseleccionan, el CI va a estar sesgado
* La dirección y tamaño del sesgo va a depender del proceso de autoselección y los datos

## 

* ¿Qué está pasando? 
* Regresemos a la definición de CI y manipulemos un poco la expresión

\[ CI= E[Y_{1i} |T_i=1]-E[Y_{0i}|T_i=0] \]

* Sumemos un cero $\color{blue}{E[Y_{0i}|T_i=1]}$

##

\begin{equation}
\begin{aligned}
 E[Y_{1i} |T_i=1]-E[Y_{0i}|T_i=0]= E[Y_{1i} |T_i=1]  \\ 
 \color{blue}{- E[Y_{0i}|T_i=1]+  E[Y_{0i}|T_i=1]} \color{black}{-E[Y_{0i}|T_i=0]}
\end{aligned}
\end{equation}

## 

Si agrupamos los térmimos, notamos que primero aparece el ATT, seguido del Sesgo de selección


\[ \text{Sesgo de Selección }= E[Y_{0i}|T_i=1]- E[Y_{0i}|T_i=0]\]

* El sesgo de selección es, en promedio, qué tan diferentes eran los tratados de los no tratados antes del tratamiento, de ahí que sea la diferencia en y0



## 

Entonces

\[ \text{CI=ATT+ Sesgo de Selección} \]

## 

* Hagamos una sola corrida para ver qué está pasando

* Intenten hacer las simulaciones en casa

##

```{r, results='hide'}
set.seed(2022)
n<-10000
i<-1:n
y0<-rnorm(n, 30, 10)
y1<-rnorm(n, 50, 35)
df<-data.frame(i,y0,y1)
# Asignamos el tratamiento
df<-mutate(df, t=ifelse(y1-y0>10,1,0) )
# Ya con el tratamiento, ponemos la y observada
df<-mutate(df,y_observada=y0+(y1-y0)*t)
# Podemos poner el efecto causal individual
df<-mutate(df, delta=y1-y0)
```


##
```{r}
df<-mutate(df, delta=y1-y0)
ate<-with(df, mean(delta))
att<-with(filter(df, t==1), mean(delta))
atc<-with(filter(df, t==0), mean(delta))
ci<-with(filter(df, t==1), 
         mean(y_observada))- 
  with(filter(df, t==0), 
       mean(y_observada))
s.bias<-with(filter(df, t==1), mean(y0))-
  with(filter(df, t==0), mean(y0))

```

##

```{r}
print(ate)
print(ci)
print(att)
print(s.bias)
```

## 

El ATE y el CI difieren por mucho. El CI es el ATT más el Sesgo de selección. El problema es que el ATT difiere enormemente del ATE porque los que se tratan son solo aquellos cuyo efecto causal es grande. Cuando hay sesgo de selección el ATE  es muy diferente al CI. 

## Ley de los grandes números

* La asignación aleatoria no asegura unconfoudedness
* Necesitamos una muestra considerable
* También, por pura chance, puede que nuestros controles y tratamientos difieran significativamente
* Podríamos hacer simulaciones cuando veamos la regresión y podamos añadir otras variables al DGP

# SUTVA

## SUTVA

A grandes rasgos, SUTVA pide:

* No Spillovers
  + Si no, confundiríamos controles con tratamiento
* Misma dósis





